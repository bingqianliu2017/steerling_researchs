# Steerling

An interpretable causal diffusion language model.

Steerling-8B combines masked diffusion language modeling with concept decomposition, enabling:
- **Generation**: Non-autoregressive text generation via confidence-based unmasking
- **Attribution**: Decompose predictions into known concept contributions
- **Steering**: Intervene on concept activations to control generation
- **Embeddings**: Extract hidden, composed, known, or unknown representations

## Quick Start

```bash
pip install steerling
```

```python
from steerling import SteerlingGenerator, GenerationConfig

generator = SteerlingGenerator.from_pretrained("guidelabs/steerling-8b")

text = generator.generate(
    "The key to understanding neural networks is",
    GenerationConfig(max_new_tokens=100, seed=42),
)
print(text)
```

## Model Details

| Property | Value |
|---|---|
| Parameters | ~8B |
| Architecture | CausalDiffusionLM + Interpretable Concept Head |
| Context Length | 4096 |
| Vocabulary | 100,281 (cl100k_base + specials) |
| Known Concepts | 33,732 |
| Unknown Concepts | 101,196 |
| GQA | 32 heads, 4 KV heads |
| Precision | bfloat16 |

## Architecture

Steerling uses block-causal attention (bidirectional within 64-token blocks, causal across blocks) with masked diffusion training. At inference, tokens are generated by iteratively unmasking positions in order of model confidence. The interpretable concept heads decompose transformer hidden states `h` into:

```
h → known_features + unk_hat + epsilon = composed → lm_head → logits
```

- `known_features`: Weighted sum of top-k learned concept embeddings
- `unk_hat`: Residual features captured by a factorized unknown head
- `epsilon`: Small correction term for reconstruction fidelity

## Installation

```bash
# From PyPI
pip install steerling

# From source
git clone https://github.com/guidelabs/steerling.git
cd steerling
pip install -e ".[dev]"

# With evaluation support
pip install -e ".[all]"
```


标准Transformer结构：
tokenizer ── transformer ── hidden  ── lm_head ── logits ── token
Steerling：
tokenizer ── transformer ── hidden ── known_features + unknown_features ── composed ── lm_head ── logits ── token
Steerling核心思想：
通过中间加入 known/unknown 分解 + 干预机制进而实现了在token生成前操纵概念激活（简单理解，可以认为在hidden和lm_head中间又加了两个线性层（known_head和unknown_head），一个计算knwon_features，一个计算unknown_features，并将值相加作为新的hidden传递给lm_head线性层）。
最终实现将hidden（完全不可解释空间）拆分成了可解释空间+不可解释空间。我们通过影响可解释空间，进而影响模型的定向生成。


https://www.guidelabs.ai/post/steerling-steering-8b/
